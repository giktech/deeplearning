{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the embeddingss (JSON file) into a python dictionary\n",
    "content = open(\"/Users/gkhanna/Google Drive/W251DeepLearning/hw6/output_mrpc.jsonl\", \"r\").read()\n",
    "data = [json.loads(str(item)) for item in content.strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Number of lines in the data list: 3\n",
      "    Type of each entry: <class 'dict'>\n",
      "    Keys in each line entry: dict_keys(['linex_index', 'features'])\n",
      "    Type of the first key (features): <class 'list'>\n",
      "    Len of the first key (features): 46\n",
      "    Type of the first entry in the features list: <class 'dict'>\n",
      "    Keys in feature list entries: dict_keys(['token', 'layers'])\n",
      "    Type of the first key (token): <class 'str'>\n",
      "    Type of the 2nd key (layers): <class 'list'>\n",
      "    Number of layers: <class 'list'>\n",
      "    Type of each layer: <class 'dict'>\n",
      "    Keys in each layer: dict_keys(['index', 'values'])\n",
      "    Type of the first key (index): <class 'int'>\n",
      "    Type of the second key (values): <class 'list'>\n",
      "    Type of each element in \"values\": <class 'float'>\n",
      "    Number of \"values\": 768\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Getting some sense of the dictionary\n",
    "print(\"\"\"\n",
    "    Number of lines in the data list: {}\n",
    "    Type of each entry: {}\n",
    "    Keys in each line entry: {}\n",
    "    Type of the first key (features): {}\n",
    "    Len of the first key (features): {}\n",
    "    Type of the first entry in the features list: {}\n",
    "    Keys in feature list entries: {}\n",
    "    Type of the first key (token): {}\n",
    "    Type of the 2nd key (layers): {}\n",
    "    Number of layers: {}\n",
    "    Type of each layer: {}\n",
    "    Keys in each layer: {}\n",
    "    Type of the first key (index): {}\n",
    "    Type of the second key (values): {}\n",
    "    Type of each element in \"values\": {}\n",
    "    Number of \"values\": {}\n",
    "    \"\"\"\n",
    "      .format (len(data), type(data[0]),data[0].keys(), type(data[0]['features']), len(data[0]['features']), \n",
    "              type(data[0]['features'][0]),data[0]['features'][0].keys(),type(data[0]['features'][0]['token']),\n",
    "              type(data[0]['features'][0]['layers']),type(data[0]['features'][0]['layers']), \n",
    "               type(data[0]['features'][0]['layers'][0]), data[0]['features'][0]['layers'][0].keys(),\n",
    "               type(data[0]['features'][0]['layers'][0]['index']),\n",
    "               type(data[0]['features'][0]['layers'][0]['values']),\n",
    "               type(data[0]['features'][0]['layers'][0]['values'][0]), \n",
    "               len(data[0]['features'][0]['layers'][0]['values'])\n",
    "                            \n",
    "              )\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] are breast pumps covered under my plan ? [SEP] i was wondering where i can find info on breast pumps and how to get one that ' s covered by my insurance . [SEP] "
     ]
    }
   ],
   "source": [
    "# Printing of a sample line\n",
    "for item in data[2]['features']:\n",
    "    print(item['token'], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# Testing of ways to get the location of [SEP]\n",
    "# We only need the first one to separate out the 2 lines\n",
    "for index, elem in enumerate(data[0]['features']):\n",
    "    if (elem['token']==\"[SEP]\"):\n",
    "        print(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on line: 0\n",
      "15\n",
      "Working on line: 1\n",
      "11\n",
      "Working on line: 2\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Creating lists a and b\n",
    "# a holds the embeddings for first sentence for the comparison, b holds the second\n",
    "# We'll use them for the similarity metrics\n",
    "# The embeddings for a sentence are made by concatenating the embeddings for each word\n",
    "a = []\n",
    "b = []\n",
    "for line_no, linex in enumerate(data):\n",
    "    a_temp = []\n",
    "    b_temp = []\n",
    "    print('Working on line:', line_no)\n",
    "    # Find the index corresponding to [SEP]\n",
    "    for index, feature in enumerate(linex['features']):\n",
    "        if (feature['token'] == '[SEP]'):\n",
    "            sep_index = index\n",
    "            print(sep_index)\n",
    "            break\n",
    "    for index, feature in enumerate(linex['features']):\n",
    "        if(feature['token'] == \"[CLS]\" or feature['token'] == \"[SEP]\"):\n",
    "            continue\n",
    "        if index < sep_index:\n",
    "            a_temp.extend(feature['layers'][0]['values'])\n",
    "        else:\n",
    "            b_temp.extend(feature['layers'][0]['values'])\n",
    "    a.append(a_temp)\n",
    "    b.append(b_temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if the lists are created fine\n",
    "len(b[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the lists to np arrays of a fixed size (max of any line)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "length_a = len(sorted(a,key=len, reverse=True)[0])\n",
    "length_b = len(sorted(b,key=len, reverse=True)[0])\n",
    "\n",
    "if length_a > length_b:\n",
    "    length = length_a\n",
    "else:\n",
    "    length = length_b\n",
    "    \n",
    "a_np=np.array([ai+[0.0]*(length-len(ai)) for ai in a])\n",
    "\n",
    "b_np=np.array([bi+[0.0]*(length-len(bi)) for bi in b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22272\n",
      "22272\n"
     ]
    }
   ],
   "source": [
    "# Testing of the arrays are the max len\n",
    "print(len(a_np[0]))\n",
    "print(len(b_np[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.252011, -0.149837,  0.299606, ..., -0.057238, -0.5152  ,\n",
       "       -2.014556])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing one of the arrays\n",
    "b_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22518777]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the cosine similarity metric\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([a_np[2]],[b_np[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2702666]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pairwise similarity metric among the arrays\n",
    "# The diag is the similarity metric between sentences in a and b\n",
    "cosine_similarity([a_np[0]],[b_np[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2702666 , 0.3519781 , 0.27356778],\n",
       "       [0.17115618, 0.34138649, 0.23624048],\n",
       "       [0.15305919, 0.25605092, 0.22518777]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(a_np, b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the embeddings for more precision in the similarity metric\n",
    "from sklearn import preprocessing\n",
    "a_np_n = preprocessing.normalize(a_np)\n",
    "b_np_n = preprocessing.normalize(b_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2702666 , 0.3519781 , 0.27356778],\n",
       "       [0.17115618, 0.34138649, 0.23624048],\n",
       "       [0.15305919, 0.25605092, 0.22518777]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity between the normalized arrays\n",
    "cosine_similarity(a_np_n, b_np_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
